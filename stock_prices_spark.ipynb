{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Stock Prices using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = 'pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_file = 'TSLA.csv'\n",
    "tesla_rdd = sc.textFile(tesla_file)\n",
    "\n",
    "amazon_file = 'AMZN.csv'\n",
    "google_file = 'GOOG.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date,Open,High,Low,Close,Adj Close,Volume',\n",
       " '2020-02-10,160.000000,163.998001,150.479996,154.255997,154.255997,123446000',\n",
       " '2020-02-11,153.757996,156.701996,151.600006,154.876007,154.876007,58487500',\n",
       " '2020-02-12,155.574005,157.949997,152.673996,153.457993,153.457993,60112500',\n",
       " '2020-02-13,148.367996,163.600006,147.000000,160.800003,160.800003,131446500']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_rdd = tesla_rdd.map(lambda row: row.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'],\n",
       " ['2020-02-10',\n",
       "  '160.000000',\n",
       "  '163.998001',\n",
       "  '150.479996',\n",
       "  '154.255997',\n",
       "  '154.255997',\n",
       "  '123446000']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = csv_rdd.first()\n",
    "tesla_df = csv_rdd.filter(lambda row : row != header).toDF(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+---------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|   Volume|\n",
      "+----------+----------+----------+----------+----------+----------+---------+\n",
      "|2020-02-10|160.000000|163.998001|150.479996|154.255997|154.255997|123446000|\n",
      "|2020-02-11|153.757996|156.701996|151.600006|154.876007|154.876007| 58487500|\n",
      "|2020-02-12|155.574005|157.949997|152.673996|153.457993|153.457993| 60112500|\n",
      "|2020-02-13|148.367996|163.600006|147.000000|160.800003|160.800003|131446500|\n",
      "|2020-02-14|157.444000|162.593994|157.100006|160.005997|160.005997| 78468500|\n",
      "+----------+----------+----------+----------+----------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tesla_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df = sqlContext.read.load(amazon_file,\n",
    "                                format='com.databricks.spark.csv',\n",
    "                                header='true',\n",
    "                                inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------+-----------+-----------+-----------+-------+\n",
      "|      Date|       Open|       High|        Low|      Close|  Adj Close| Volume|\n",
      "+----------+-----------+-----------+-----------+-----------+-----------+-------+\n",
      "|2020-02-10| 2085.01001|2135.600098|2084.959961|2133.909912|2133.909912|5056200|\n",
      "|2020-02-11|2150.899902|2185.949951|     2136.0|2150.800049|2150.800049|5746000|\n",
      "|2020-02-12|2163.199951|    2180.25|2155.290039|     2160.0|     2160.0|3334300|\n",
      "|2020-02-13| 2144.98999|2170.280029|     2142.0|2149.870117|2149.870117|3031800|\n",
      "|2020-02-14|2155.679932|2159.040039|2125.889893|2134.870117|2134.870117|2606200|\n",
      "+----------+-----------+-----------+-----------+-----------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amazon_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amazon_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2085.010010</td>\n",
       "      <td>2135.600098</td>\n",
       "      <td>2084.959961</td>\n",
       "      <td>2133.909912</td>\n",
       "      <td>2133.909912</td>\n",
       "      <td>5056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>2150.899902</td>\n",
       "      <td>2185.949951</td>\n",
       "      <td>2136.000000</td>\n",
       "      <td>2150.800049</td>\n",
       "      <td>2150.800049</td>\n",
       "      <td>5746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>2163.199951</td>\n",
       "      <td>2180.250000</td>\n",
       "      <td>2155.290039</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>3334300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>2144.989990</td>\n",
       "      <td>2170.280029</td>\n",
       "      <td>2142.000000</td>\n",
       "      <td>2149.870117</td>\n",
       "      <td>2149.870117</td>\n",
       "      <td>3031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>2155.679932</td>\n",
       "      <td>2159.040039</td>\n",
       "      <td>2125.889893</td>\n",
       "      <td>2134.870117</td>\n",
       "      <td>2134.870117</td>\n",
       "      <td>2606200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "0  2020-02-10  2085.010010  2135.600098  2084.959961  2133.909912   \n",
       "1  2020-02-11  2150.899902  2185.949951  2136.000000  2150.800049   \n",
       "2  2020-02-12  2163.199951  2180.250000  2155.290039  2160.000000   \n",
       "3  2020-02-13  2144.989990  2170.280029  2142.000000  2149.870117   \n",
       "4  2020-02-14  2155.679932  2159.040039  2125.889893  2134.870117   \n",
       "\n",
       "     Adj Close   Volume  \n",
       "0  2133.909912  5056200  \n",
       "1  2150.800049  5746000  \n",
       "2  2160.000000  3334300  \n",
       "3  2149.870117  3031800  \n",
       "4  2134.870117  2606200  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore and Query Data\n",
    "\n",
    "#### DataFrames operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_df = sqlContext.read.load(google_file,\n",
    "                                format='com.databricks.spark.csv',\n",
    "                                header='true',\n",
    "                                inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|  yr|        avg(Close)|\n",
      "+----+------------------+\n",
      "|2020|1485.8534564933911|\n",
      "|2021|1869.0388558461536|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "google_df.select(F.year('Date').alias('yr'), 'Close').groupby('yr').avg('Close').sort('yr').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+\n",
      "|year|month|          avg(Low)|\n",
      "+----+-----+------------------+\n",
      "|2020|    2| 2053.253574928571|\n",
      "|2020|    3|1825.1590964090908|\n",
      "|2020|    4|2185.9347679523808|\n",
      "|2020|    5|     2364.48549805|\n",
      "|2020|    6| 2579.099553909091|\n",
      "|2020|    7|2991.4899903636356|\n",
      "|2020|    8|3207.5033250476195|\n",
      "|2020|    9|3109.7995023809526|\n",
      "|2020|   10| 3185.981367681817|\n",
      "|2020|   11|3102.2170043999995|\n",
      "|2020|   12|3166.3018133636365|\n",
      "|2021|    1|3171.6500051052626|\n",
      "|2021|    2|3298.1542968571425|\n",
      "+----+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amazon_df.select(F.year('Date').alias('year'),\n",
    "                F.month('Date').alias('month'),\n",
    "                'Low',)\\\n",
    "         .groupby('year', 'month').avg('Low').sort('year', 'month')\\\n",
    "         .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.registerTempTable('amazon_stocks')\n",
    "tesla_df.registerTempTable('tesla_stocks')\n",
    "google_df.registerTempTable('google_stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_amazon = 'select year(Date) as year, month(Date) as month, round(avg(Close), 2) as avg_close from amazon_stocks group by year, month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+\n",
      "|year|month|avg_close|\n",
      "+----+-----+---------+\n",
      "|2020|    6|  2613.55|\n",
      "|2020|   11|  3141.81|\n",
      "|2020|    3|  1872.31|\n",
      "|2020|    9|  3160.75|\n",
      "|2020|   12|  3197.75|\n",
      "+----+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(query_amazon).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_google = 'select Date, Open, Close, round(abs(Open - Close),2) as diff from google_stocks where abs(Open - Close) > 4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------+-----+\n",
      "|      Date|       Open|      Close| diff|\n",
      "+----------+-----------+-----------+-----+\n",
      "|2020-02-10|1474.319946|1508.680054|34.36|\n",
      "|2020-02-14|1515.599976| 1520.73999| 5.14|\n",
      "|2020-02-18|     1515.0|1519.670044| 4.67|\n",
      "|2020-02-21|1508.030029|1485.109985|22.92|\n",
      "|2020-02-24|1426.109985|1421.589966| 4.52|\n",
      "+----------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(query_google).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tesla = 'SELECT year(Date) year,\\\n",
    "                round(max(`Adj Close`), 2) max_adj_close,\\\n",
    "                round(min(`Adj Close`), 2) min_adj_close \\\n",
    "                FROM tesla_stocks\\\n",
    "                GROUP BY year(Date)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-------------+\n",
      "|year|max_adj_close|min_adj_close|\n",
      "+----+-------------+-------------+\n",
      "|2020|        96.31|       100.43|\n",
      "|2021|       883.09|       729.77|\n",
      "+----+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(query_tesla).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_join = 'SELECT t.Date, round(t.Close, 2) tesla_close , round(a.Close, 2) amazon_close, round(g.Close, 2) google_close\\\n",
    "              FROM tesla_stocks t \\\n",
    "              JOIN google_stocks g on t.Date = g.Date \\\n",
    "              JOIN amazon_stocks a on a.Date = t.Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_close_df = sqlContext.sql(query_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------+------------+\n",
      "|      Date|tesla_close|amazon_close|google_close|\n",
      "+----------+-----------+------------+------------+\n",
      "|2020-02-10|     154.26|     2133.91|     1508.68|\n",
      "|2020-02-11|     154.88|      2150.8|     1508.79|\n",
      "|2020-02-12|     153.46|      2160.0|     1518.27|\n",
      "|2020-02-13|      160.8|     2149.87|     1514.66|\n",
      "|2020-02-14|     160.01|     2134.87|     1520.74|\n",
      "+----------+-----------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_close_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Spark DataFrames\n",
    "#### Parquet - column oriented storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parquet (overwrite if exists)\n",
    "join_close_df.write.format('parquet').mode('overwrite').save('join_stock.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------+------------+\n",
      "|      Date|tesla_close|amazon_close|google_close|\n",
      "+----------+-----------+------------+------------+\n",
      "|2020-02-10|     154.26|     2133.91|     1508.68|\n",
      "|2020-02-11|     154.88|      2150.8|     1508.79|\n",
      "|2020-02-12|     153.46|      2160.0|     1518.27|\n",
      "|2020-02-13|      160.8|     2149.87|     1514.66|\n",
      "|2020-02-14|     160.01|     2134.87|     1520.74|\n",
      "+----------+-----------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load saved parquet back\n",
    "final_df = sqlContext.read.parquet('join_stock.parquet')\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- tesla_close: double (nullable = true)\n",
      " |-- amazon_close: double (nullable = true)\n",
      " |-- google_close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
